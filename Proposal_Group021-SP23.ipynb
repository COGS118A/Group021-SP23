{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Shantelle Serafin\n",
    "- Jason Krentsel\n",
    "- Jackie Lai\n",
    "- Zecheng (Justin) Li"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Our goal is to categorize text found within tweets as hate speech, offensive language, or being neither. The data set we are using is representative of actual tweets on twitter and are measured by crowd-sourced opinions of which category best fits each tweet. We will be using this data to train an algorithm to determine if tweets contain hate speech and/or offensive language to then determine if it would be appropriate to flag the tweet or ban the user. Performance will be measured based on accuracy of classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Offensive speech and hate speech is prolific on the internet, one could argue that it is more easily found there than in the real world. This abundance could be due to a number of factors, including but not limited to anonymity, invisibility, community, and instantaneousness<a name=\"brown\"></a>[<sup>[1]</sup>](#brownnote). Because of the anonymity and real physical distance between speaker and recipient, the internet has become a place where it is safe, and sometimes even encouraged, to engage in hate culture as there are much fewer real-world repercussions. Resultantly, social media companies are facing lots of criticism and backlash from governments, causing them to be more “proactive in anticipating corrupted use of their online platforms.” <a name=\"ulgen\"></a>[<sup>[2]</sup>](#ulgennote) However, the “constantly evolving nature of and variety of cyberhate”<a name=\"brown\"></a>[<sup>[1]</sup>](#brownnote) makes this not only practically difficult but could potentially lead to misflagging of tweets or accounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem we are solving is the classification of Tweets into 3 different categories: hate speech, offensive language, or neither. We want to develop a machine learning model that can accurately predict a novel tweets class for possible use in automatically moderating the site. One of the more complex parts of creating such a model is turning text into quantitative data. While this is far from impossible, there are many natural language processing techniques we can utilize which can maintain varying amounts of semantic information. After tokenizing a tweet, we can use a Term Frequency-Inverse Document Frequency (TF-IDF) strategy to generate a value of how important each word is to a tweet. This is quite a powerful technique because not all offensive tweets are hateful. For example, “I f***ing love this movie” would obviously be flagged for offensive language, but the importance of the offensive word is low and could signify non-hateful meaning. On the other hand, hateful language doesn’t necessarily have to have offensive content, ex. “I think the director of this movie should never show their face in public after that terrible movie”. The main error metric we want to use is false positive rate. As this would be an automatic moderating system, we want to only allow it to ban users only when it is very sure that their tweets are offensive or hateful. We can use a more lenient system for flagging tweets for human moderation where our model might miss, but it would not be good for it to accidentally ban users that did not post malicious content. Malicious text content on the internet is arguably some of the most replicable data there can be. There is a constant flow of tweets being published, and even when they are not neatly organized in a dataset, we can always utilize Twitter’s API to scrape for more data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "- https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset\n",
    "- 24784 observations, with 7 variables\n",
    "- An observation consists of [count of human classifier votes, hate speech votes, offensive language votes, neither votes, final classification (plural vote), tweet text]\n",
    "- The main critical variables is the final classification and the raw tweet text\n",
    "- We will need to use various natural language processing techniques to turn the raw tweet text into quantifiable values. We will most likely utilize bag-of-words and Term Frequency-Inverse Document Frequency to convert this text data into numerical values.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Our proposed solution for the problem is to implement a supervised machine learning model for classifying the tweets into the 3 categories: hate speech, offensive language, or neither. We believe that this approach could provide a high accuracy in distinguishing hate speech and offensive language from normal language in tweets.\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "We will use the Natural Language Toolkit (NLTK) and other Python libraries to preprocess the tweet text data. This includes cleaning the text, converting to lowercase, tokenizing, removing stop words, and lemmatizing.\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "    # Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return tokens\n",
    "```\n",
    "\n",
    "## Vectorization\n",
    "\n",
    "For vectorization, we will use the Term Frequency-Inverse Document Frequency (TF-IDF) strategy. This will help us to determine the importance of each word to a tweet. We will use the TfidfVectorizer from the sklearn.feature_extraction.text module.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialization\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Vectorization function\n",
    "def vectorize_text(tokens):\n",
    "    vector = vectorizer.fit_transform(tokens)\n",
    "    return vector\n",
    "```\n",
    "\n",
    "## Algorithms\n",
    "\n",
    "We will train several models using different algorithms, including Naive Bayes, Support Vector Machines (SVM), Logistic Regression, and Deep Learning models such as RNNs or Transformers. We choose these algorithms because they are well-known for their effectiveness in text classification tasks.\n",
    "\n",
    "1. **Naive Bayes**: Naive Bayes classifiers are based on applying Bayes' theorem, which is a formula to calculate conditional probabilities. The formula for Bayes' theorem is:\n",
    "\n",
    "    P(c|d) = [P(d|c) * P(c)] / P(d)\n",
    "\n",
    "   Where:\n",
    "   - P(c|d) is the posterior probability of class c given predictor (features).\n",
    "   - P(d|c) is the likelihood which is the probability of predictor given class.\n",
    "   - P(c) is the prior probability of class.\n",
    "   - P(d) is the prior probability of predictor.\n",
    "\n",
    "2. **Support Vector Machines (SVM)**: The goal of SVM is to find the optimal hyperplane which maximizes the margin between the two classes. In two dimentional space, this hyperplane is a line. The distance between the hyperplane and the nearest data point from either set is known as the margin. The goal is to choose a hyperplane with the greatest possible margin. The loss function that helps maximize this margin is hinge loss defined as:\n",
    "\n",
    "   L(y) = max(0, 1 - y)\n",
    "\n",
    "   Where:\n",
    "   - y is the dot product of the weights (derived from the data) and the input vectors.\n",
    "\n",
    "3. **Logistic Regression**: Logistic regression uses a logistic function to model a binary dependent variable. The logistic function also known as sigmoid function is an S-shaped curve that can take any real-valued number and map it into a value between 0 and 1, but never exactly at those limits. The hypothesis of logistic regression tends it to limit the cost function between 0 and 1. The logistic function is defined as:\n",
    "\n",
    "   h(x) = 1 / (1 + e^(-x))\n",
    "\n",
    "   Where:\n",
    "   - h(x) is the predicted output,\n",
    "   - x is the input to the function,\n",
    "   - e is the base of natural logarithms.\n",
    "\n",
    "4. **Deep Learning (Neural Networks)**: Neural networks consist of input and output layers, as well as (in most cases) a hidden layer consisting of units that transform the input into something that the output layer can use. The most simple neural network is the perceptron, which, in its simplest form, consists of a single neuron. Much like logistic regression, it's a binary classifier that uses a threshold function. But for multilayer perceptrons, an activation function is used. The most commonly used activation function is the ReLU function:\n",
    "\n",
    "   f(x) = max(0, x)\n",
    "\n",
    "   Where:\n",
    "   - f(x) is the output of the activation function,\n",
    "   - x is the input to the function.\n",
    "\n",
    "For text classification tasks, these models are usually trained in a supervised manner, using a training dataset to learn a mapping from input documents to output class labels. This mapping is then used to predict the class labels of new, unseen documents. <a name=\"chatgpt\"></a>[<sup>[3]</sup>](#chatgpt)\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Models initialization\n",
    "nb_model = MultinomialNB()\n",
    "svm_model = SVC()\n",
    "lr_model = LogisticRegression()\n",
    "```\n",
    "\n",
    "For the deep learning model, we will use the Keras library in TensorFlow.<a name=\"chatgpt\"></a>[<sup>[3]</sup>](#chatgpt)\n",
    "```python\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "# LSTM model initialization\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=5000, output_dim=32))\n",
    "lstm_model.add(LSTM(100))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "```\n",
    "\n",
    "## Benchmark Model\n",
    "\n",
    "As a benchmark, we will compare the results of our models against a simple Bag-of-Words model. This model will be implemented using the CountVectorizer from sklearn.<a name=\"chatgpt\"></a>[<sup>[3]</sup>](#chatgpt) Or we can also compare the results of the baseline model of Logistic Regression.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialization\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "# Vectorization function\n",
    "def bow_vectorize_text(tokens):\n",
    "    vector = bow_vectorizer.fit_transform(tokens)\n",
    "    return vector\n",
    "```\n",
    "\n",
    "By comparing our models to this simple model, we can assess the improvements our more complex models provide.\n",
    "\n",
    "## Model Training and Evaluation\n",
    "\n",
    "Once we have preprocessed and vectorized our data, we will split it into training and test sets using sklearn's train_test_split function. Then, we can train each of our models on the training data and evaluate them on the test data.<a name=\"chatgpt\"></a>[<sup>[3]</sup>](#chatgpt)\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the models\n",
    "nb_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
    "```\n",
    "\n",
    "We'll evaluate the models using accuracy as our primary metric, but we will also look at the confusion matrix to understand how the model is making errors.<a name=\"chatgpt\"></a>[<sup>[3]</sup>](#chatgpt)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Making predictions\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lstm_predictions = lstm_model.predict_classes(X_test)\n",
    "\n",
    "# Evaluating the models\n",
    "print(\"Naive Bayes Accuracy: \", accuracy_score(y_test, nb_predictions))\n",
    "print(\"SVM Accuracy: \", accuracy_score(y_test, svm_predictions))\n",
    "print(\"Logistic Regression Accuracy: \", accuracy_score(y_test, lr_predictions))\n",
    "print(\"LSTM Accuracy: \", accuracy_score(y_test, lstm_predictions))\n",
    "```\n",
    "\n",
    "## Making the Solution Reproducible\n",
    "\n",
    "To ensure that our solution is reproducible, we will provide the full code for data preprocessing, model training, and evaluation in a Jupyter notebook. This will allow others to replicate our results, validate our approach, and even build upon our work.\n",
    "\n",
    "## Further Improvement\n",
    "\n",
    "While this is our proposed solution, there are always opportunities for improvement. For example, we could experiment with different vectorization methods, like Word2Vec or GloVe. We could also try using more complex models, like BERT or GPT, which have been shown to provide state-of-the-art performance on a range of text classification tasks. These models are available in the transformers library from Hugging Face.\n",
    "\n",
    "Lastly, we can fine-tune our models using techniques like grid search to find the optimal hyperparameters that we learned from class. This can be done using GridSearchCV from sklearn.model_selection.\n",
    "\n",
    "By following these steps, we believe we can develop a robust and efficient model for classifying tweets into hate speech, offensive language, or neither."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "In the context of our problem statement, precision is an essential metric because we are highly concerned about minimizing false positives. In this case, a false positive would mean our model wrongly classifies a tweet as hate speech or offensive language, potentially leading to an undeserved ban or flag for the user. This could have significant consequences for the user experience and the overall trust in the platform. Therefore, we aim to maximize the precision of our model.\n",
    "\n",
    "### Precision\n",
    "\n",
    "Precision, also known as the positive predictive value, quantifies the model's ability to avoid labeling non-hateful or non-offensive tweets as hateful or offensive. Mathematically, precision is defined as the ratio of true positives (TP) to the sum of true positives and false positives (FP):\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "Where:\n",
    "- TP = True Positives: The instances where the model correctly predicted a tweet as hate speech or offensive language.\n",
    "- FP = False Positives: The instances where the model incorrectly flagged a non-offensive tweet as offensive or hate speech.\n",
    "\n",
    "The higher the precision, the lower the false positive rate, and the fewer innocent users will get flagged or banned.\n",
    "\n",
    "For instance, if our model flags 100 tweets as offensive, and 85 of them are indeed offensive, the precision of our model would be 85/100 = 0.85 or 85%. This implies that 85% of the users flagged by the system as offensive were correctly identified.\n",
    "\n",
    "However, precision alone may not provide the full picture of our model's performance. It does not consider false negatives (actual offensive tweets that the model failed to flag), which are also a concern. To get a more comprehensive understanding, we might consider other metrics like recall or F1 score in conjunction with precision. But given our specific objective of reducing user banning due to misclassification, precision becomes our primary metric.\n",
    "\n",
    "Thus, while building the model, we aim to maximize precision to ensure that the users are not wrongly flagged or banned due to the misclassification of their tweets as hate speech or offensive language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that we are going to classify whether or not a tweet is hateful or offensive, there may be ethical concerns. Firstly, if the classifier were to perform inaccurately it can cause harm to many people. For example, if it classifies a tweet that is not hateful as hateful, then it can impede on someone's freedom of speech. Second, if it classifies a tweet that is hateful that is not hateful, it can damage a person's mental wellbeing. Our team plans to prioritize reducing misses over false alarms in order to protect the mental health of the users at scale. Contrastingly, because the tweets are posted to the public we are not concerned with privacy issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Our team will communicate in a kind, direct, and respectful manner with each other either over text or in person in all aspects of the project*\n",
    "* *Our team will equally and fully contribute to all aspects of the project in order to be turned in before the deadline*\n",
    "* *Our team will be honest in all aspects of the project*\n",
    "* *On-time attendance is required in each team meeting*\n",
    "* *In the case of an absence, 24 hour notice of meeting cancellation is required *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 5/9  |  4 PM | NA  | Ideate and choose project, divide and conquer project proposal | \n",
    "| 5/17  |  Before 8 PM | Team members complete their assigned parts | Proposal Due  | \n",
    "| 5/22  | 7 PM  | Team members read peer review instructions  | Complete peer review proposal, divide and conquer   |\n",
    "| 5/24  | Before 8 PM  | Team members complete their assigned parts | Peer Review Due   |\n",
    "| 5/25 | 7 PM  | Team members review peer feedback | Start project with feedback, prep data, divide work, complete checkpoint |\n",
    "| 5/31  | Before 8 PM  | Team members complete their assigned parts| Checkpoint Due |\n",
    "| 6/7  | 7 PM  | NA | Compile all completed work, bug fixes, final details  |\n",
    "| 6/14  | Before 8 PM  | Team members finish final details | Final Project Due  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"brownnote\"></a>1.[^](#brown): Brown, Alexander. “What Is so Special about Online (as Compared to Offline) Hate Speech?” Ethnicities, vol. 18, no. 3, 2018, pp. 297–326. JSTOR, https://www.jstor.org/stable/26497929. Accessed 18 May 2023. <br>\n",
    "<a name=\"ulgennote\"></a>2.[^](#ulgen): Ülgen, Sinan. “FREEDOM OF EXPRESSION ONLINE.” GOVERNING CYBERSPACE: A Road Map for Transatlantic Leadership, Carnegie Endowment for International Peace, 2016, pp. 17–28. JSTOR, http://www.jstor.org/stable/resrep26924.7. Accessed 18 May 2023.<br>\n",
    "<a name=\"chatgptnote\"></a>3.[^](#chatgpt): ChatGPT, OpenAI. Personal communication for technical assistance, formatting, and provision of sample code. May 2023.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
